================================================================================
ü§ñ AutoML Agent - Direct Mode
================================================================================
You are to generate TWO files:

1.  model.py - A Python file that includes:

-   A PyTorch model class (nn.Module) appropriate for the dataset.
-   A train() function that trains the model for multiple epochs.
-   A validate() function that evaluates the model on a validation dataset and reports metrics.
-   An if __name__ == '__main__' block with argparse CLI.
-   Only output the code

CRITICAL REQUIREMENTS:

1.  ARGPARSE INTERFACE - Use these EXACT argument names: --train (path to training data) --val (path to validation data) --epochs (number of epochs) --batch-size (batch size) --lr (learning rate). Default the epochs, batch size, and learning rate to reasonable values based on common practices.

2.  DEVICE HANDLING - MUST support both CPU and GPU: device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'). Ensure that the model and data are moved to the appropriate device in both train() and validate() functions.

3.  TRAINING LOOP - Proper structure:
    -   The train function should accept epochs as a parameter and run the full training loop.
    -   Print the average loss per epoch (not just the last batch).
    -   In the main block, call train() ONCE with all epochs, not in a loop.

4.  LOGGING - Print after each epoch: Epoch X/Y: Train Loss: 0.XXXX, Train Acc: XX.XX%, Val Loss: 0.XXXX, Val Acc: XX.XX%.

5.  CHECKPOINTING - Save the model when the validation metric improves: torch.save(model.state_dict(), 'best_model.pth'). Print a message when saving: 'Saved best model (Val Acc: XX.XX%)'.

6.  CODE QUALITY:
    -   Use clear and descriptive variable names.
    -   Add docstrings to all functions.
    -   Handle edge cases (e.g., empty datasets, etc.).

7.  DEPENDENCIES - ONLY use these libraries:
    -   torch (and torch.nn, torch.optim, torch.utils.data)
    -   pandas (for CSV reading)
    -   numpy (optional)
    -   torchvision (ONLY for ImageFolder OR transfer learning)

Dataset Description: CIFAR 100 dataset

Dataset schema facts: {
  "train_path": "datasets/cifar100_train.csv",
  "val_path": "datasets/cifar100_test.csv",
  "type": "csv",
  "n_columns": 3073,
  "task": "regression",
  "n_classes": null,
  "sample_shape": "1000 rows \u00d7 3073 columns",
  "split_type": "csv"
}

Dataset type Specific handling: 
- Task: Classification with None classes
- Loss: CrossEntropyLoss
- Metrics: Accuracy

DATASET TYPE: CSV Image Data
 - CSV rows contain: label + flattened pixel values
 - Automatically infer image shape and channels from row length:
        num_pixels = len(row) - 1  # exclude label
        if (num_pixels ** 0.5).is_integer():
             height = width = int(num_pixels ** 0.5)
             channels = 1  # single-channel grayscale
        else:
             height = width = int((num_pixels // 3) ** 0.5)
             channels = 3  # multi-channel image
 - After reshaping into (H,W,C) or (C,H,W), the model.py MUST:
       - Convert NumPy ‚Üí PIL using transforms.ToPILImage()
       - Apply PIL-based torchvision transforms (Resize, ColorJitter, etc.)
       - Convert back to tensor using transforms.ToTensor()        
 - transforms must run on PIL images, NOT on raw tensors
 - Correct preprocessing pipeline MUST be:
        img = img.reshape(H, W, C)
        img = transforms.ToPILImage()(img)
        img = transform_pipeline(img)  
 - Normalization MUST use ImageNet statistics when using pretrained models:
        mean = [0.485, 0.456, 0.406]
        std  = [0.229, 0.224, 0.225]
 - If the image is grayscale, convert to 3-channel AFTER converting to tensor:
        if tensor.shape[0] == 1:
            tensor = tensor.repeat(3,1,1)

MODEL ARCHITECTURE REQUIREMENTS: 
- Transfer learning must be preferred when it improves accuracy. If transfer learning fits the dataset (e.g., 3-channel images), the generated model.py should:
    - Use a pretrained model such as ResNet18 or MobileNetV3
    - Freeze all pretrained layers:
        for param in model.parameters():
            param.requires_grad = False

    - Replace the classifier head with a new Linear layer of correct output size
    - Use adaptive pooling or a dummy forward pass to compute flatten size dynamically

- If transfer learning is NOT appropriate:
  - (e.g., tiny grayscale dataset), generate a small CNN.
- Aim for >90% accuracy.
- The model MUST compute the flatten dimension dynamically during initialization using a dummy forward pass. Do NOT hardcode the input size to the fully-connected layer. Define all layers used in forward() before calling the flatten-size computation helper.
- In forward(), flatten using torch.flatten(x, 1) ‚Äî NEVER use x.view(-1, fixed_number).

EXAMPLE STRUCTURE (follow this pattern):

    # Code outline...

2.  requirements.txt - List all pip packages needed (one per line). Include version constraints if important. Packages: torch, torchvision, pandas, numpy, pillow.

OUTPUT FORMAT - Use this EXACT structure: 
=== requirements.txt ===
package1
package2>=version

=== model.py === 
import package1 # ‚Ä¶ rest of the file

Calling LLM to generate initial code and dependencies...
‚úì Obtained initial model from LangGraph pipeline.
‚úì Wrote requirements.txt
‚úì Wrote model.py
Requirement already satisfied: torch in /opt/pytorch/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.8.0+cu129)
Requirement already satisfied: torchvision in /opt/pytorch/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.23.0+cu129)
Requirement already satisfied: pandas in /opt/pytorch/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.3.3)
Requirement already satisfied: numpy in /opt/pytorch/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.26.4)
Requirement already satisfied: pillow in /opt/pytorch/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (12.0.0)
Requirement already satisfied: filelock in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.20.0)
Requirement already satisfied: typing-extensions>=4.10.0 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (4.15.0)
Requirement already satisfied: setuptools in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (80.9.0)
Requirement already satisfied: sympy>=1.13.3 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (1.14.0)
Requirement already satisfied: networkx in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.5)
Requirement already satisfied: jinja2 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.1.6)
Requirement already satisfied: fsspec in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (2025.10.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.9.86 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (12.9.86)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.9.79 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (12.9.79)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.9.79 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (12.9.79)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.9.1.4 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (12.9.1.4)
Requirement already satisfied: nvidia-cufft-cu12==11.4.1.4 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (11.4.1.4)
Requirement already satisfied: nvidia-curand-cu12==10.3.10.19 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (10.3.10.19)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.5.82 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (11.7.5.82)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.10.65 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (12.5.10.65)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (2.27.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.9.79 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (12.9.79)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.9.86 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (12.9.86)
Requirement already satisfied: nvidia-cufile-cu12==1.14.1.1 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (1.14.1.1)
Requirement already satisfied: triton==3.4.0 in /opt/pytorch/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.4.0)
Requirement already satisfied: python-dateutil>=2.8.2 in /opt/pytorch/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in /opt/pytorch/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)
Requirement already satisfied: tzdata>=2022.7 in /opt/pytorch/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)
Requirement already satisfied: six>=1.5 in /opt/pytorch/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 3)) (1.17.0)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/pytorch/lib/python3.12/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in /opt/pytorch/lib/python3.12/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.3)

=== Iteration 1/3 ===
Wrote model.py


‚ö†Ô∏è Model training produced errors:
 /opt/pytorch/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/opt/pytorch/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/opt/pytorch/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

  0%|          | 0.00/44.7M [00:00<?, ?B/s]
  2%|‚ñè         | 1.00M/44.7M [00:00<00:04, 10.3MB/s]
  4%|‚ñç         | 2.00M/44.7M [00:00<00:04, 10.2MB/s]
  7%|‚ñã         | 3.12M/44.7M [00:00<00:04, 10.8MB/s]
 28%|‚ñà‚ñà‚ñä       | 12.5M/44.7M [00:00<00:00, 44.7MB/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 38.4M/44.7M [00:00<00:00, 125MB/s] 
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:00<00:00, 87.9MB/s]
/root/autoMLSystemBuilder/model.py:24: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  label = row[0]

Model output:
 Downloading: "https://download.pytorch.org/models/resnet18-f37072fd.pth" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth
Epoch 1/1: Train Loss: 2.6383, Train Acc: 35.56%
Epoch 1/10: Val Loss: 2.0652, Val Acc: 46.61%
Saved best model (Val Acc: 46.61%)
Epoch 1/1: Train Loss: 2.0243, Train Acc: 47.09%
Epoch 2/10: Val Loss: 2.0045, Val Acc: 47.09%
Saved best model (Val Acc: 47.09%)
Epoch 1/1: Train Loss: 1.9228, Train Acc: 49.03%
Epoch 3/10: Val Loss: 1.9495, Val Acc: 48.82%
Saved best model (Val Acc: 48.82%)
Epoch 1/1: Train Loss: 1.8762, Train Acc: 50.41%
Epoch 4/10: Val Loss: 1.9051, Val Acc: 49.45%
Saved best model (Val Acc: 49.45%)
Epoch 1/1: Train Loss: 1.8451, Train Acc: 50.68%
Epoch 5/10: Val Loss: 1.8920, Val Acc: 50.29%
Saved best model (Val Acc: 50.29%)
Epoch 1/1: Train Loss: 1.8314, Train Acc: 51.45%
Epoch 6/10: Val Loss: 1.8980, Val Acc: 50.29%
Epoch 1/1: Train Loss: 1.8036, Train Acc: 52.12%
Epoch 7/10: Val Loss: 1.9044, Val Acc: 50.38%
Saved best model (Val Acc: 50.38%)
Epoch 1/1: Train Loss: 1.7864, Train Acc: 52.43%
Epoch 8/10: Val Loss: 1.8601, Val Acc: 51.13%
Saved best model (Val Acc: 51.13%)
Epoch 1/1: Train Loss: 1.7794, Train Acc: 52.25%
Epoch 9/10: Val Loss: 1.9203, Val Acc: 49.80%
Epoch 1/1: Train Loss: 1.7716, Train Acc: 52.62%
Epoch 10/10: Val Loss: 1.8684, Val Acc: 51.64%
Saved best model (Val Acc: 51.64%)

Extracted metrics: {'val_loss': 1.8601, 'val_acc': 51.64}
‚úÖ New best model found (Val Loss: 1.8601)
Refinement iteration complete ‚Äî model updated.

=== Iteration 2/3 ===
Wrote model.py

‚ö†Ô∏è Model training produced errors:
 /opt/pytorch/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/opt/pytorch/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/opt/pytorch/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/root/autoMLSystemBuilder/model.py:24: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  label = row[0]

Model output:
 Epoch 1/1: Train Loss: 4.3973, Train Acc: 6.61%
Epoch 1/20: Val Loss: 3.9094, Val Acc: 19.96%
Saved best model (Val Acc: 19.96%)
Epoch 1/1: Train Loss: 3.8892, Train Acc: 17.78%
Epoch 2/20: Val Loss: 3.4863, Val Acc: 31.86%
Saved best model (Val Acc: 31.86%)
Epoch 1/1: Train Loss: 3.6713, Train Acc: 22.45%
Epoch 3/20: Val Loss: 3.2381, Val Acc: 37.71%
Saved best model (Val Acc: 37.71%)
Epoch 1/1: Train Loss: 3.5411, Train Acc: 25.34%
Epoch 4/20: Val Loss: 3.0514, Val Acc: 41.80%
Saved best model (Val Acc: 41.80%)
Epoch 1/1: Train Loss: 3.4719, Train Acc: 26.58%
Epoch 5/20: Val Loss: 2.9480, Val Acc: 43.19%
Saved best model (Val Acc: 43.19%)
Epoch 1/1: Train Loss: 3.4124, Train Acc: 27.60%
Epoch 6/20: Val Loss: 2.8443, Val Acc: 45.44%
Saved best model (Val Acc: 45.44%)
Epoch 1/1: Train Loss: 3.3792, Train Acc: 27.89%
Epoch 7/20: Val Loss: 2.7750, Val Acc: 46.37%
Saved best model (Val Acc: 46.37%)
Epoch 1/1: Train Loss: 3.3517, Train Acc: 28.74%
Epoch 8/20: Val Loss: 2.7192, Val Acc: 47.19%
Saved best model (Val Acc: 47.19%)
Epoch 1/1: Train Loss: 3.3481, Train Acc: 28.58%
Epoch 9/20: Val Loss: 2.6768, Val Acc: 47.96%
Saved best model (Val Acc: 47.96%)
Epoch 1/1: Train Loss: 3.3134, Train Acc: 29.11%
Epoch 10/20: Val Loss: 2.6351, Val Acc: 47.91%
Epoch 1/1: Train Loss: 3.2956, Train Acc: 29.57%
Epoch 11/20: Val Loss: 2.6100, Val Acc: 48.69%
Saved best model (Val Acc: 48.69%)
Epoch 1/1: Train Loss: 3.2789, Train Acc: 29.91%
Epoch 12/20: Val Loss: 2.5722, Val Acc: 49.31%
Saved best model (Val Acc: 49.31%)
Epoch 1/1: Train Loss: 3.2768, Train Acc: 29.95%
Epoch 13/20: Val Loss: 2.5619, Val Acc: 49.19%
Epoch 1/1: Train Loss: 3.2568, Train Acc: 30.35%
Epoch 14/20: Val Loss: 2.5381, Val Acc: 49.80%
Saved best model (Val Acc: 49.80%)
Epoch 1/1: Train Loss: 3.2533, Train Acc: 30.42%
Epoch 15/20: Val Loss: 2.5131, Val Acc: 50.02%
Saved best model (Val Acc: 50.02%)
Epoch 1/1: Train Loss: 3.2439, Train Acc: 30.45%
Epoch 16/20: Val Loss: 2.5085, Val Acc: 50.15%
Saved best model (Val Acc: 50.15%)
Epoch 1/1: Train Loss: 3.2408, Train Acc: 30.51%
Epoch 17/20: Val Loss: 2.4809, Val Acc: 50.38%
Saved best model (Val Acc: 50.38%)
Epoch 1/1: Train Loss: 3.2224, Train Acc: 30.95%
Epoch 18/20: Val Loss: 2.4762, Val Acc: 49.92%
Epoch 1/1: Train Loss: 3.2103, Train Acc: 31.00%
Epoch 19/20: Val Loss: 2.4544, Val Acc: 51.03%
Saved best model (Val Acc: 51.03%)
Epoch 1/1: Train Loss: 3.2236, Train Acc: 30.77%
Epoch 20/20: Val Loss: 2.4566, Val Acc: 50.28%

Extracted metrics: {'val_loss': 2.4544, 'val_acc': 51.03}
Refinement iteration complete ‚Äî model updated.

=== Iteration 3/3 ===
Wrote model.py
