You are to generate TWO files:

1.  model.py - A Python file that includes:

-   A PyTorch model class (nn.Module) appropriate for the dataset.
-   A train() function that trains the model for multiple epochs.
-   A validate() function that evaluates the model on a validation
    dataset and reports metrics.
-   An if __name__ == '__main__' block with argparse CLI.

CRITICAL REQUIREMENTS:

1.  ARGPARSE INTERFACE - Use these EXACT argument names: --train (path to
    training data) --val (path to validation data) --epochs (number of
    epochs) --batch-size (batch size) --lr
    (learning rate). Default the epochs, batchsize and learning rate to whatever makes sense.

2.  DEVICE HANDLING - MUST support both CPU and GPU: device =
    torch.device(‘cuda’ if torch.cuda.is_available() else ‘cpu’) Move
    model and data to device in train/validate functions

3.  TRAINING LOOP - Proper structure:

    -   Train function should accept epochs parameter and run full
        training loop
    -   Print average loss per epoch (not just last batch)
    -   In main: call train() ONCE with all epochs, not in a loop

4.  LOGGING - Print after each epoch: Epoch X/Y: Train Loss: 0.XXXX,
    Train Acc: XX.XX%, Val Loss: 0.XXXX, Val Acc: XX.XX%

5.  CHECKPOINTING - Save model when validation metric improves:
    torch.save(model.state_dict(), ‘best_model.pth’) Print message when
    saving: ‘Saved best model (Val Acc: XX.XX%)’

6.  CODE QUALITY:
    -   Use proper variable names
    -   Add docstrings to functions
    -   Handle edge cases (empty datasets, etc.)

7.  DEPENDENCIES - ONLY use these libraries:
    -   torch (and torch.nn, torch.optim, torch.utils.data)
    -   pandas (for CSV reading)
    -   numpy (optional)
    -   torchvision (ONLY for ImageFolder OR transfer learning) 

Dataset Description: {{dataset_description}}

Dataset schema facts: {{facts_json_here}}

Dataset type Specific handling: 
{{dataset_type_specific_handling}}


MODEL ARCHITECTURE REQUIREMENTS: 
- Goal is to get >90% accuracy
- Use the simplest architecture that would get good results.
- Use transfer learning if it makes sense for the problem. If using transfer learning, freeze all pretrained weights.
- Use best fitting deep learning architecture for the dataset
- Replace the final FC layer with correct output dimension.

EXAMPLE STRUCTURE (follow this pattern):
```
    # Code outline...
```

2.  requirements.txt - List all pip packages needed (one per line)
    Include version constraints if important. Packages: torch,
    torchvision, pandas, numpy, pillow

OUTPUT FORMAT - Use this EXACT structure: 
=== requirements.txt ===
package1
package2>=version

=== model.py === 
import package1 # … rest of the file

IMPORTANT: Use the === markers exactly as shown. No markdown code
fences, no explanations.